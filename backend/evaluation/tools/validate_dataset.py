"""
ë°ì´í„°ì…‹ ê²€ì¦ ë„êµ¬

í‰ê°€ ë°ì´í„°ì…‹ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬:
1. ìŠ¤í‚¤ë§ˆ ê²€ì¦
2. Ground Truth ë¬¸ì„œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
3. ë°ì´í„° ë¶„í¬ ë¶„ì„
"""

import json
from pathlib import Path
from typing import Optional

from evaluation.schemas import EvalDataset
from evaluation.tools.dataset_builder import DatasetBuilder
from evaluation.config import eval_settings, QUERY_TYPE_DISTRIBUTION


class DatasetValidator:
    """
    ë°ì´í„°ì…‹ ê²€ì¦ê¸°

    Usage:
        validator = DatasetValidator()
        report = await validator.validate("evaluation/datasets/eval_dataset_v1.json")
        print(report)
    """

    def __init__(self):
        self.errors: list[str] = []
        self.warnings: list[str] = []
        self.info: list[str] = []

    async def validate(
        self,
        dataset_path: str,
        check_documents: bool = True,
    ) -> dict:
        """
        ë°ì´í„°ì…‹ ê²€ì¦

        Args:
            dataset_path: ë°ì´í„°ì…‹ ê²½ë¡œ
            check_documents: Ground Truth ë¬¸ì„œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸

        Returns:
            ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        self.errors = []
        self.warnings = []
        self.info = []

        path = Path(dataset_path)
        if not path.is_absolute():
            path = eval_settings.datasets_dir / dataset_path

        if not path.exists():
            self.errors.append(f"ë°ì´í„°ì…‹ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {path}")
            return self._build_report()

        try:
            builder = DatasetBuilder.load(path)
            dataset = builder.dataset
        except Exception as e:
            self.errors.append(f"ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return self._build_report()

        self._validate_schema(dataset)
        self._validate_ids(dataset)
        self._validate_content(dataset)
        self._analyze_distribution(dataset)

        if check_documents:
            await self._check_documents_exist(dataset)

        return self._build_report()

    def _validate_schema(self, dataset: EvalDataset) -> None:
        """ìŠ¤í‚¤ë§ˆ ê²€ì¦"""
        if not dataset.name:
            self.errors.append("ë°ì´í„°ì…‹ ì´ë¦„ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")

        if not dataset.queries:
            self.warnings.append("ë°ì´í„°ì…‹ì— ì¿¼ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤")

        self.info.append(f"ì´ ì¿¼ë¦¬ ìˆ˜: {len(dataset.queries)}")

    def _validate_ids(self, dataset: EvalDataset) -> None:
        """ID ìœ íš¨ì„± ê²€ì¦"""
        ids = [q.id for q in dataset.queries]

        if len(ids) != len(set(ids)):
            duplicates = [id for id in ids if ids.count(id) > 1]
            self.errors.append(f"ì¤‘ë³µëœ ì¿¼ë¦¬ ID: {set(duplicates)}")

        for query in dataset.queries:
            if not query.id.startswith("Q-"):
                self.warnings.append(f"ë¹„í‘œì¤€ ì¿¼ë¦¬ ID í˜•ì‹: {query.id}")

    def _validate_content(self, dataset: EvalDataset) -> None:
        """ë‚´ìš© ê²€ì¦"""
        for query in dataset.queries:
            if not query.question.strip():
                self.errors.append(f"{query.id}: ì§ˆë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")

            if len(query.question) < 10:
                self.warnings.append(f"{query.id}: ì§ˆë¬¸ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ ({len(query.question)}ì)")

            if len(query.question) > 500:
                self.warnings.append(f"{query.id}: ì§ˆë¬¸ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤ ({len(query.question)}ì)")

            if not query.ground_truth.source_documents:
                self.errors.append(f"{query.id}: Ground Truth ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")

            if not query.ground_truth.key_points:
                self.warnings.append(f"{query.id}: Key Pointsê°€ ì—†ìŠµë‹ˆë‹¤")

    def _analyze_distribution(self, dataset: EvalDataset) -> None:
        """ë¶„í¬ ë¶„ì„"""
        if not dataset.queries:
            return

        by_category: dict[str, int] = {}
        by_type: dict[str, int] = {}
        by_difficulty: dict[str, int] = {}

        for query in dataset.queries:
            cat = query.metadata.category.value
            by_category[cat] = by_category.get(cat, 0) + 1

            qtype = query.metadata.query_type.value
            by_type[qtype] = by_type.get(qtype, 0) + 1

            diff = query.metadata.difficulty.value
            by_difficulty[diff] = by_difficulty.get(diff, 0) + 1

        total = len(dataset.queries)

        self.info.append(f"ì¹´í…Œê³ ë¦¬ ë¶„í¬: {by_category}")
        self.info.append(f"ì¿¼ë¦¬ ìœ í˜• ë¶„í¬: {by_type}")
        self.info.append(f"ë‚œì´ë„ ë¶„í¬: {by_difficulty}")

        for qtype, target_ratio in QUERY_TYPE_DISTRIBUTION.items():
            actual_count = by_type.get(qtype, 0)
            actual_ratio = actual_count / total if total > 0 else 0
            target_count = int(total * target_ratio)

            if actual_count < target_count * 0.5:
                self.warnings.append(
                    f"'{qtype}' ì¿¼ë¦¬ ë¶€ì¡±: {actual_count}ê°œ (ëª©í‘œ: {target_count}ê°œ, {target_ratio*100:.0f}%)"
                )

    async def _check_documents_exist(self, dataset: EvalDataset) -> None:
        """Ground Truth ë¬¸ì„œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        import sys
        sys.path.insert(0, str(Path(__file__).parent.parent.parent))

        from sqlalchemy import select
        from app.core.database import async_session_factory
        from app.models.precedent_document import PrecedentDocument
        from app.models.law_document import LawDocument

        precedent_ids = set()
        law_ids = set()

        for query in dataset.queries:
            for doc in query.ground_truth.source_documents:
                if doc.doc_type.value == "precedent":
                    precedent_ids.add(doc.doc_id)
                else:
                    law_ids.add(doc.doc_id)

        async with async_session_factory() as session:
            if precedent_ids:
                result = await session.execute(
                    select(PrecedentDocument.serial_number)
                )
                existing_precedents = {r[0] for r in result}
                missing = precedent_ids - existing_precedents
                if missing:
                    self.errors.append(f"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íŒë¡€: {missing}")

            if law_ids:
                result = await session.execute(
                    select(LawDocument.law_id)
                )
                existing_laws = {r[0] for r in result}
                missing = law_ids - existing_laws
                if missing:
                    self.errors.append(f"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë²•ë ¹: {missing}")

    def _build_report(self) -> dict:
        """ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±"""
        return {
            "valid": len(self.errors) == 0,
            "errors": self.errors,
            "warnings": self.warnings,
            "info": self.info,
            "summary": {
                "error_count": len(self.errors),
                "warning_count": len(self.warnings),
            },
        }


async def main():
    """CLI ì‹¤í–‰"""
    import argparse
    import asyncio

    parser = argparse.ArgumentParser(description="ë°ì´í„°ì…‹ ê²€ì¦")
    parser.add_argument(
        "dataset",
        type=str,
        help="ê²€ì¦í•  ë°ì´í„°ì…‹ ê²½ë¡œ",
    )
    parser.add_argument(
        "--skip-doc-check",
        action="store_true",
        help="ë¬¸ì„œ ì¡´ì¬ ì—¬ë¶€ ê²€ì‚¬ ìƒëµ",
    )

    args = parser.parse_args()

    validator = DatasetValidator()
    report = await validator.validate(
        args.dataset,
        check_documents=not args.skip_doc_check,
    )

    print("\n=== ë°ì´í„°ì…‹ ê²€ì¦ ê²°ê³¼ ===\n")

    if report["valid"]:
        print("âœ… ìœ íš¨í•œ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\n")
    else:
        print("âŒ ë°ì´í„°ì…‹ì— ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤.\n")

    if report["errors"]:
        print("ğŸ”´ ì˜¤ë¥˜:")
        for error in report["errors"]:
            print(f"  - {error}")
        print()

    if report["warnings"]:
        print("ğŸŸ¡ ê²½ê³ :")
        for warning in report["warnings"]:
            print(f"  - {warning}")
        print()

    if report["info"]:
        print("â„¹ï¸ ì •ë³´:")
        for info in report["info"]:
            print(f"  - {info}")


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
