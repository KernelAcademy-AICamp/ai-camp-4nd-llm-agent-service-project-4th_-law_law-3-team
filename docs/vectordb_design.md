# ë²•ë¥  ë²¡í„° DB êµ¬ì¶• ì„¤ê³„ ë¬¸ì„œ

## ë°ì´í„° ì†ŒìŠ¤

### JSON ì›ë³¸
| ë°ì´í„° | íŒŒì¼ ê²½ë¡œ | ê±´ìˆ˜ |
|--------|-----------|------|
| ë²•ë ¹ | `data/law_cleaned.json` | 5,841ê±´ |
| íŒë¡€ | `data/precedents_cleaned.json` | 65,107ê±´ |

### PostgreSQL í…Œì´ë¸” (LanceDB ì „ìš©)
| í…Œì´ë¸” | ì„¤ëª… | ë¹„ê³  |
|--------|------|------|
| `law_documents` | ë²•ë ¹ ì›ë³¸ ë°ì´í„° | LanceDB ê²€ìƒ‰ í›„ ì›ë³¸ ì¡°íšŒìš© |
| `precedent_documents` | íŒë¡€ ì›ë³¸ ë°ì´í„° | ruling, claim, reasoning ë“± ì „ì²´ í…ìŠ¤íŠ¸ ì €ì¥ |
| `legal_documents` | ê¸°ì¡´ í…Œì´ë¸” | ChromaDB í˜¸í™˜ (ìœ ì§€) |

---

## 1. ìŠ¤í‚¤ë§ˆ ì„¤ê³„ (v2 - ë‹¨ì¼ í…Œì´ë¸” + NULL)

### ì„¤ê³„ ì›ì¹™
- ëª¨ë“  í•„ë“œë¥¼ ê°œë³„ ì»¬ëŸ¼ìœ¼ë¡œ ì •ì˜ (JSON metadata ì‚¬ìš© ì•ˆ í•¨)
- í•´ë‹¹í•˜ì§€ ì•ŠëŠ” í•„ë“œëŠ” NULL
- `data_type` ì»¬ëŸ¼ìœ¼ë¡œ ë¬¸ì„œ ìœ í˜• êµ¬ë¶„ ("ë²•ë ¹" | "íŒë¡€")

### PyArrow ìŠ¤í‚¤ë§ˆ
```python
LEGAL_CHUNKS_SCHEMA = pa.schema([
    # ========== ê³µí†µ í•„ë“œ (10ê°œ) ==========
    pa.field("id", pa.utf8()),              # ì²­í¬ ê³ ìœ  ID (ì˜ˆ: "010719_0")
    pa.field("source_id", pa.utf8()),       # ì›ë³¸ ë¬¸ì„œ ID (ì˜ˆ: "010719")
    pa.field("data_type", pa.utf8()),       # "ë²•ë ¹" | "íŒë¡€"
    pa.field("title", pa.utf8()),           # ì œëª© (ë²•ë ¹ëª… / ì‚¬ê±´ëª…)
    pa.field("content", pa.utf8()),         # ì²­í¬ í…ìŠ¤íŠ¸ (prefix í¬í•¨)
    pa.field("vector", pa.list_(pa.float32(), 1024)),  # ì„ë² ë”© ë²¡í„° (KURE 1024ì°¨ì›)
    pa.field("date", pa.utf8()),            # ë‚ ì§œ (ë²•ë ¹: ì‹œí–‰ì¼, íŒë¡€: ì„ ê³ ì¼)
    pa.field("source_name", pa.utf8()),     # ì¶œì²˜ (ë²•ë ¹: ì†Œê´€ë¶€ì²˜, íŒë¡€: ë²•ì›ëª…)
    pa.field("chunk_index", pa.int32()),    # ì²­í¬ ì¸ë±ìŠ¤
    pa.field("total_chunks", pa.int32()),   # í•´ë‹¹ ë¬¸ì„œì˜ ì´ ì²­í¬ ìˆ˜

    # ========== ë²•ë ¹ ì „ìš© (íŒë¡€ëŠ” NULL) ==========
    pa.field("promulgation_date", pa.utf8()),   # ê³µí¬ì¼ì (ì˜ˆ: "20230808")
    pa.field("promulgation_no", pa.utf8()),     # ê³µí¬ë²ˆí˜¸ (ì˜ˆ: "19592")
    pa.field("law_type", pa.utf8()),            # ë²•ë ¹ ìœ í˜• (ë²•ë¥ /ì‹œí–‰ë ¹/ì‹œí–‰ê·œì¹™)
    pa.field("article_no", pa.utf8()),          # ì¡°ë¬¸ ë²ˆí˜¸ (ì˜ˆ: "ì œ750ì¡°")

    # ========== íŒë¡€ ì „ìš© (ë²•ë ¹ì€ NULL) ==========
    # NOTE: ruling, claim, reasoningì€ PostgreSQL precedent_documents í…Œì´ë¸”ì—ì„œ ì¡°íšŒ
    pa.field("case_number", pa.utf8()),         # ì‚¬ê±´ë²ˆí˜¸ (ì˜ˆ: "84ë‚˜3990")
    pa.field("case_type", pa.utf8()),           # ì‚¬ê±´ ìœ í˜• (ë¯¼ì‚¬/í˜•ì‚¬/í–‰ì •)
    pa.field("judgment_type", pa.utf8()),       # íŒê²° ë²•ì›ë¶€ (ì˜ˆ: "ì œ11ë¯¼ì‚¬ë¶€íŒê²°")
    pa.field("judgment_status", pa.utf8()),     # íŒê²° ìƒíƒœ (í™•ì •/ë¯¸í™•ì •)
    pa.field("reference_provisions", pa.utf8()),# ì°¸ì¡° ì¡°ë¬¸ (ì˜ˆ: "ë¯¼ë²• ì œ750ì¡°, ì œ756ì¡°")
    pa.field("reference_cases", pa.utf8()),     # ì°¸ì¡° íŒë¡€
])
# ì´ 20ê°œ ì»¬ëŸ¼ (ê¸°ì¡´ 23ê°œì—ì„œ ruling, claim, reasoning 3ê°œ ì œê±°)
```

### ì»¬ëŸ¼ ê·¸ë£¹ (ì´ 20ê°œ)
```python
COMMON_COLUMNS = [  # 10ê°œ
    "id", "source_id", "data_type", "title", "content",
    "vector", "date", "source_name", "chunk_index", "total_chunks"
]

LAW_COLUMNS = [  # 4ê°œ
    "promulgation_date", "promulgation_no", "law_type", "article_no"
]

PRECEDENT_COLUMNS = [  # 6ê°œ (ruling, claim, reasoning ì œê±°)
    "case_number", "case_type", "judgment_type",
    "judgment_status", "reference_provisions", "reference_cases"
]
```

---

## 2. í•„ë“œ ë§¤í•‘

| ìŠ¤í‚¤ë§ˆ í•„ë“œ | ë²•ë ¹ ì›ë³¸ í•„ë“œ | íŒë¡€ ì›ë³¸ í•„ë“œ |
|-------------|----------------|----------------|
| `id` | `{law_id}_{chunk_idx}` | `{íŒë¡€ì •ë³´ì¼ë ¨ë²ˆí˜¸}_{chunk_idx}` |
| `source_id` | `law_id` | `íŒë¡€ì •ë³´ì¼ë ¨ë²ˆí˜¸` |
| `data_type` | "ë²•ë ¹" | "íŒë¡€" |
| `title` | `law_name` | `ì‚¬ê±´ëª…` |
| `content` | ì¡°ë¬¸ë²ˆí˜¸ + ì¡°ë¬¸ë‚´ìš© | prefix + íŒì‹œì‚¬í•­ + íŒê²°ìš”ì§€ |
| `date` | `enforcement_date` | `ì„ ê³ ì¼ì` |
| `source_name` | `ministry` | `ë²•ì›ëª…` |
| `chunk_index` | ì²­í¬ ìˆœë²ˆ | ì²­í¬ ìˆœë²ˆ |
| `total_chunks` | í•´ë‹¹ ë¬¸ì„œ ì´ ì²­í¬ ìˆ˜ | í•´ë‹¹ ë¬¸ì„œ ì´ ì²­í¬ ìˆ˜ |
| `promulgation_date` | `ê³µí¬ì¼ì` | NULL |
| `promulgation_no` | `ê³µí¬ë²ˆí˜¸` | NULL |
| `law_type` | `ë²•ë ¹ìœ í˜•` | NULL |
| `article_no` | `ì¡°ë¬¸ë²ˆí˜¸` | NULL |
| `case_number` | NULL | `ì‚¬ê±´ë²ˆí˜¸` |
| `case_type` | NULL | `ì‚¬ê±´ì¢…ë¥˜ëª…` |
| `judgment_type` | NULL | `íŒê²°ìœ í˜•` |
| `judgment_status` | NULL | `íŒê²°ìƒíƒœ` |
| `reference_provisions` | NULL | `ì°¸ì¡°ì¡°ë¬¸` |
| `reference_cases` | NULL | `ì°¸ì¡°íŒë¡€` |

> **NOTE**: `ruling`, `claim`, `reasoning`ì€ LanceDBì— ì €ì¥í•˜ì§€ ì•ŠìŒ (ë©”ëª¨ë¦¬ íš¨ìœ¨í™”).
> ê²€ìƒ‰ í›„ PostgreSQL `precedent_documents` í…Œì´ë¸”ì—ì„œ ì¡°íšŒí•˜ì—¬ ì ‘ê·¼.

---

## 2.5. ê²€ìƒ‰ íë¦„ (PostgreSQL ì—°ë™)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ì‚¬ìš©ì ì¿¼ë¦¬      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LanceDB ë²¡í„° ê²€ìƒ‰ â”‚ â† ì„ë² ë”© ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ source_id ì¶”ì¶œ   â”‚ â† ë²•ë ¹: law_id, íŒë¡€: serial_number
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL ì›ë³¸ ì¡°íšŒ                                  â”‚
â”‚   - ë²•ë ¹: law_documents (law_idë¡œ ì¡°íšŒ)              â”‚
â”‚   - íŒë¡€: precedent_documents (serial_numberë¡œ ì¡°íšŒ) â”‚
â”‚     â†’ ruling, claim, full_reason ë“± ì „ì²´ í…ìŠ¤íŠ¸ ì ‘ê·¼ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì½”ë“œ ì˜ˆì‹œ
```python
# 1. LanceDB ë²¡í„° ê²€ìƒ‰
results = store.search(query_embedding, n_results=10, where={"data_type": "íŒë¡€"})

# 2. source_id ì¶”ì¶œ
source_ids = [meta["source_id"] for meta in results.metadatas[0]]

# 3. PostgreSQLì—ì„œ ì›ë³¸ ì¡°íšŒ
from app.models.precedent_document import PrecedentDocument
from sqlalchemy import select

async with async_session_factory() as session:
    query = select(PrecedentDocument).where(
        PrecedentDocument.serial_number.in_(source_ids)
    )
    result = await session.execute(query)
    originals = {doc.serial_number: doc for doc in result.scalars()}

# 4. ruling, claim, reasoning ì ‘ê·¼
for source_id in source_ids:
    doc = originals.get(source_id)
    if doc:
        print(f"ì£¼ë¬¸: {doc.ruling}")
        print(f"ì²­êµ¬ì·¨ì§€: {doc.claim}")
        print(f"ì´ìœ : {doc.full_reason}")
```

---

## 3. ì²­í‚¹ ì „ëµ

### ë²•ë ¹ ì²­í‚¹
- **split_mode**: ì¡°ë¬¸(\n\n) ë¶„ë¦¬ â†’ í† í° ì´ˆê³¼ ì‹œ í•­(â‘ â‘¡â‘¢) ë‹¨ìœ„ë¡œ ì¶”ê°€ ë¶„ë¦¬
- **max_tokens**: 800
- **min_tokens**: 100
- **prefix_mode**: ì œ3ì¡° â‘  í˜•íƒœ

**ë™ì‘ ë°©ì‹:**
1. ì¡°ë¬¸ ë‹¨ìœ„(`\n\n`)ë¡œ 1ì°¨ ë¶„ë¦¬
2. ì¡°ë¬¸ì´ 800 í† í° ì´ˆê³¼ ì‹œ â†’ í•­(â‘ â‘¡â‘¢) ë‹¨ìœ„ë¡œ 2ì°¨ ë¶„ë¦¬
3. 100 í† í° ë¯¸ë§Œ ì²­í¬ â†’ ì¸ì ‘ ì²­í¬ì™€ ë³‘í•©
4. prefix í˜•ì‹: `ì œNì¡° â‘ ` (ë²•ë ¹ëª… ì œì™¸, ì¡°ë¬¸ë²ˆí˜¸ë§Œ)

### íŒë¡€ ì²­í‚¹
- **ìµœëŒ€ ê¸¸ì´**: 1250ì
- **ì˜¤ë²„ë©**: 10% (125ì)

**ë™ì‘ ë°©ì‹:**
1. **íŒì‹œì‚¬í•­ + íŒê²°ìš”ì§€ë§Œ ì‚¬ìš©** (ì´ìœ , ì£¼ë¬¸ ë“± ì œì™¸)
2. 1250ì ì´ˆê³¼ ì‹œ ì˜¤ë²„ë© ì²­í‚¹ ì ìš©
3. prefix í˜•ì‹: `[ë²•ì›ëª… ì‚¬ê±´ë²ˆí˜¸]`

---

## 4. ID êµ¬ì¡° ë° í™œìš©

### ID í˜•ì‹
```
{source_id}_{chunk_index}
```

### í™œìš© ë°©ë²•
```python
# ID íŒŒì‹±
id = "010719_2"
source_id = id.rsplit("_", 1)[0]  # "010719"
chunk_index = int(id.rsplit("_", 1)[1])  # 2

# ê°™ì€ ë¬¸ì„œì˜ ëª¨ë“  ì²­í¬ ì¡°íšŒ
all_chunks = store.get_by_source_id(source_id)

# ì›ë³¸ ìˆœì„œëŒ€ë¡œ ì •ë ¬ (ìë™ ì •ë ¬ë¨)
sorted_chunks = all_chunks["documents"]

# ì „ì²´ ë¬¸ì„œ ë³µì›
full_content = "\n".join(sorted_chunks)
```

---

## 5. ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
backend/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ common/
â”‚       â””â”€â”€ vectorstore/
â”‚           â”œâ”€â”€ __init__.py          # íŒ©í† ë¦¬ ë° export
â”‚           â”œâ”€â”€ base.py              # VectorStoreBase ì¸í„°í˜ì´ìŠ¤
â”‚           â”œâ”€â”€ schema_v2.py         # LanceDB ìŠ¤í‚¤ë§ˆ v2 (ë‹¨ì¼ í…Œì´ë¸” + NULL)
â”‚           â”œâ”€â”€ lancedb.py           # LanceDBStore êµ¬í˜„ì²´
â”‚           â”œâ”€â”€ chroma.py            # ChromaDB êµ¬í˜„ì²´ (ê¸°ì¡´)
â”‚           â””â”€â”€ qdrant.py            # Qdrant êµ¬í˜„ì²´ (ê¸°ì¡´)
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ create_lancedb_embeddings.py # LanceDB ì„ë² ë”© ìƒì„± ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ data/
    â””â”€â”€ lancedb/                     # LanceDB ë°ì´í„° ì €ì¥ì†Œ
```

---

## 6. êµ¬í˜„ ìƒíƒœ

### ì™„ë£Œ
- [x] ìŠ¤í‚¤ë§ˆ ì •ì˜ (`schema_v2.py`) - ë‹¨ì¼ í…Œì´ë¸” + NULL ë°©ì‹ (20ê°œ ì»¬ëŸ¼)
- [x] LanceDBStore êµ¬í˜„ (`lancedb.py`) - v2 ìŠ¤í‚¤ë§ˆ ê¸°ë°˜
- [x] PostgreSQL ëª¨ë¸ (`law_document.py`, `precedent_document.py`)
- [x] Alembic ë§ˆì´ê·¸ë ˆì´ì…˜ (`003_add_lancedb_tables.py`)
- [x] ë°ì´í„° ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ (`load_lancedb_data.py`) - JSON â†’ PostgreSQL
- [x] ì„ë² ë”© ìŠ¤í¬ë¦½íŠ¸ (`create_lancedb_embeddings.py`) - PostgreSQL â†’ LanceDB
- [x] ruling, claim, reasoning ì œê±° (ë©”ëª¨ë¦¬ íš¨ìœ¨í™”)
- [x] **íŒë¡€ ë°ì´í„° ì „ì²´ ì„ë² ë”©** (65,107ê±´ â†’ 134,846 ì²­í¬)
- [x] **ë²•ë ¹ ë°ì´í„° ì „ì²´ ì„ë² ë”©** (5,841ê±´ â†’ 118,922 ì²­í¬)
- [x] **í†µí•© ì„ë² ë”© í”„ë¡œì„¸ì„œ í´ë˜ìŠ¤** (`StreamingEmbeddingProcessor`)
- [x] **ì²­í‚¹ ë¬´í•œë£¨í”„ ë²„ê·¸ ìˆ˜ì •** (2026-01-29)

### ì§„í–‰ ì˜ˆì •
- [ ] ê²€ìƒ‰ API ì—°ë™ (LanceDB â†’ í”„ë¡ íŠ¸ì—”ë“œ)
- [ ] í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + í‚¤ì›Œë“œ) êµ¬í˜„
- [ ] ê²€ìƒ‰ ê²°ê³¼ ìºì‹±

---

## 7. ì‹¤í–‰ ëª…ë ¹

```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
uv sync

# Hugging Face ë¡œê·¸ì¸ (KURE ëª¨ë¸ ì ‘ê·¼ìš©)
huggingface-cli login

# í™˜ê²½ë³€ìˆ˜ ì„¤ì • (.env)
VECTOR_DB=lancedb
LANCEDB_URI=./data/lancedb
LANCEDB_TABLE_NAME=legal_chunks

# ========== Step 1: PostgreSQL ë§ˆì´ê·¸ë ˆì´ì…˜ ==========
cd backend
alembic upgrade head

# ========== Step 2: JSON â†’ PostgreSQL ë°ì´í„° ë¡œë“œ ==========
# ë²•ë ¹ ë°ì´í„° ë¡œë“œ
uv run python scripts/load_lancedb_data.py --type law

# íŒë¡€ ë°ì´í„° ë¡œë“œ
uv run python scripts/load_lancedb_data.py --type precedent

# ì „ì²´ ë¡œë“œ (ë²•ë ¹ + íŒë¡€)
uv run python scripts/load_lancedb_data.py --type all

# ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ì¬ë¡œë“œ
uv run python scripts/load_lancedb_data.py --type all --reset

# í†µê³„ í™•ì¸
uv run python scripts/load_lancedb_data.py --stats

# ========== Step 3: PostgreSQL â†’ LanceDB ì„ë² ë”© ìƒì„± ==========
# íŒë¡€ ì„ë² ë”© ìƒì„± (precedent_documents í…Œì´ë¸”ì—ì„œ)
uv run python scripts/create_lancedb_embeddings.py --type precedent

# ë²•ë ¹ ì„ë² ë”© ìƒì„± (law_documents í…Œì´ë¸”ì—ì„œ)
uv run python scripts/create_lancedb_embeddings.py --type law

# ì „ì²´ (íŒë¡€ + ë²•ë ¹)
uv run python scripts/create_lancedb_embeddings.py --type all

# ì „ì²´ ì¬ìƒì„± (ê¸°ì¡´ ë°ì´í„° ì‚­ì œ)
uv run python scripts/create_lancedb_embeddings.py --type all --reset

# í†µê³„ í™•ì¸
uv run python scripts/create_lancedb_embeddings.py --stats

# ========== ì˜µì…˜ ==========
# íŒë¡€ ì˜µì…˜
--batch-size 100      # ë°°ì¹˜ í¬ê¸° (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •)
--chunk-size 1250     # íŒë¡€ ì²­í¬ í¬ê¸° (ê¸°ë³¸ê°’)
--chunk-overlap 125   # íŒë¡€ ì˜¤ë²„ë© (ê¸°ë³¸ê°’ 10%)

# ë²•ë ¹ ì˜µì…˜
--max-tokens 800      # ë²•ë ¹ ì²­í¬ ìµœëŒ€ í† í° (ê¸°ë³¸ê°’)
--min-tokens 100      # ë²•ë ¹ ì²­í¬ ìµœì†Œ í† í° (ê¸°ë³¸ê°’)
```

---

## 8. ê²€ì¦ ê³„íš

### ì²­í‚¹ ê²€ì¦
- [ ] ë²•ë ¹: 800 í† í° ì´í•˜, 100 í† í° ì´ìƒì¸ì§€ í™•ì¸
- [ ] íŒë¡€: 1250ì ì´í•˜, ì˜¤ë²„ë© ì •ìƒ ì ìš© í™•ì¸
- [ ] prefixê°€ ì˜¬ë°”ë¥´ê²Œ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸

### ìŠ¤í‚¤ë§ˆ ê²€ì¦
- [ ] í•„ìˆ˜ í•„ë“œ ëˆ„ë½ ì—†ëŠ”ì§€ í™•ì¸
- [ ] data_typeë³„ NULL í•„ë“œ ì •ìƒ ì—¬ë¶€ í™•ì¸
- [ ] id í˜•ì‹ ì¼ê´€ì„± í™•ì¸

### ê²€ìƒ‰ ê²€ì¦
- [ ] ë™ì¼ ì¿¼ë¦¬ë¡œ ë²•ë ¹/íŒë¡€ ëª¨ë‘ ê²€ìƒ‰ë˜ëŠ”ì§€ í™•ì¸
- [ ] data_type í•„í„°ë§ ì •ìƒ ì‘ë™ í™•ì¸
- [ ] source_idë¡œ ì›ë³¸ ë¬¸ì„œ ë³µì› ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸

---

## 9. ì„¤ê³„ ê²°ì • ìš”ì•½

| í•­ëª© | ê²°ì • | ì´ìœ  |
|------|------|------|
| DB | LanceDB (ë‹¨ì¼ í…Œì´ë¸”) | í†µí•© ê²€ìƒ‰ ìš©ì´, ë””ìŠ¤í¬ ê¸°ë°˜ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  |
| ë©”íƒ€ë°ì´í„° | **ê°œë³„ ì»¬ëŸ¼ + NULL (20ê°œ)** | JSONë³´ë‹¤ í•„í„°ë§ 5.8x ë¹ ë¦„ |
| ì„ë² ë”© ëª¨ë¸ | KURE-v1 (1024ì°¨ì›) | í•œêµ­ì–´ ìµœì í™”, ìµœê³  ì„±ëŠ¥ |
| í•„í„° ì»¬ëŸ¼ | date, source_name ë“± | ìì£¼ ì‚¬ìš©í•˜ëŠ” í•„í„° ìµœì í™” |
| ë²•ë ¹ ì²­í‚¹ | hybrid (800/100 í† í°) | Test B ì¡°ê±´ ì ìš©, ì¡°ë¬¸-í•­ êµ¬ì¡° ë³´ì¡´ |
| íŒë¡€ ì²­í‚¹ | 1250ì + 10% ì˜¤ë²„ë© | ì„ë² ë”© ëª¨ë¸ ì œí•œ ê³ ë ¤ |
| íŒë¡€ ì„ë² ë”© ëŒ€ìƒ | íŒì‹œì‚¬í•­ + íŒê²°ìš”ì§€ë§Œ | í•µì‹¬ ë²•ë¦¬ ì¤‘ì‹¬ ê²€ìƒ‰ |
| ID êµ¬ì¡° | source_id_chunkIdx | ì›ë³¸ ì¶”ì  + ì²­í¬ ì‹ë³„ |
| ruling/claim/reasoning | **PostgreSQL ì €ì¥** | ë©”ëª¨ë¦¬ íš¨ìœ¨í™”, ê²€ìƒ‰ í›„ ì›ë³¸ ì¡°íšŒ |
| ë°ì´í„° íë¦„ | JSON â†’ PostgreSQL â†’ LanceDB | í˜¸í™˜ì„± + í™•ì¥ì„± |

---

## 10. RunPod/Colab ì„ë² ë”© (GPU í™˜ê²½)

ëŒ€ìš©ëŸ‰ ë°ì´í„° ì„ë² ë”©ì„ ìœ„í•œ GPU í™˜ê²½ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.

### ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜
```
backend/scripts/
â”œâ”€â”€ runpod_lancedb_embeddings.py  # RunPod GPUìš© (ë¶„í•  ì²˜ë¦¬ í¬í•¨)
â”œâ”€â”€ runpod_split_embeddings.py    # ë¶„í•  ì „ìš© (ê°„ì†Œí™” ë²„ì „)
â””â”€â”€ colab_lancedb_embeddings.py   # Google Colabìš©
```

### ë¶„í•  ì²˜ë¦¬ ë°©ì‹ (ê¶Œì¥)

ëŒ€ìš©ëŸ‰ íŒë¡€ ë°ì´í„°(6ë§Œê±´+)ëŠ” ë©”ëª¨ë¦¬ ë¬¸ì œë¡œ ë¶„í•  ì²˜ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.

**ë‘ ê°€ì§€ ë¶„í• ì˜ ì°¨ì´:**
| ë¶„í•  ìœ í˜• | ë‹¨ìœ„ | ìš©ë„ |
|-----------|------|------|
| `split_precedents(chunk_size=5000)` | íŒë¡€ ê±´ìˆ˜ | íŒŒì¼ ë¶„í•  (ë©”ëª¨ë¦¬ ì ˆì•½) |
| `PRECEDENT_CHUNK_SIZE=1250` | ê¸€ì ìˆ˜ | ì„ë² ë”© í…ìŠ¤íŠ¸ ë¶„í•  |

### ì‚¬ìš©ë²• (RunPod Jupyter)

```python
# 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜
!pip install lancedb sentence-transformers pyarrow ijson psutil tqdm gdown -q

# 2. ë°ì´í„° ë‹¤ìš´ë¡œë“œ (Google Driveì—ì„œ)
!gdown --id YOUR_FILE_ID -O precedents_cleaned.json
!gdown --id YOUR_FILE_ID -O law_cleaned.json

# 3. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
exec(open('runpod_lancedb_embeddings.py').read())

# 4. ë””ë°”ì´ìŠ¤ í™•ì¸
print_device_info()

# 5. íŒë¡€ ë¶„í•  ì²˜ë¦¬ (ê¶Œì¥)
split_precedents('precedents_cleaned.json', chunk_size=5000)
run_all_precedent_parts('precedents_part_*.json', batch_size=64)

# 6. ë²•ë ¹ ë¶„í•  ì²˜ë¦¬
split_laws('law_cleaned.json', chunk_size=2000)
run_all_law_parts('laws_part_*.json', batch_size=64)

# 7. ê²°ê³¼ í™•ì¸
show_stats()

# 8. ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
!zip -r lancedb_data.zip ./lancedb_data
```

### í•¨ìˆ˜ ëª©ë¡

| í•¨ìˆ˜ | ì„¤ëª… |
|------|------|
| `print_device_info()` | GPU/ë””ë°”ì´ìŠ¤ ì •ë³´ ì¶œë ¥ |
| `print_memory_status()` | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ |
| `split_precedents(path, chunk_size)` | íŒë¡€ JSON íŒŒì¼ ë¶„í•  |
| `split_laws(path, chunk_size)` | ë²•ë ¹ JSON íŒŒì¼ ë¶„í•  |
| `run_precedent_embedding_part(path, reset, batch_size)` | ë¶„í• ëœ íŒë¡€ íŒŒì¼ ì²˜ë¦¬ |
| `run_all_precedent_parts(pattern, batch_size)` | ëª¨ë“  ë¶„í•  íŒë¡€ íŒŒì¼ ì²˜ë¦¬ |
| `run_law_embedding_part(path, reset, batch_size)` | ë¶„í• ëœ ë²•ë ¹ íŒŒì¼ ì²˜ë¦¬ |
| `run_all_law_parts(pattern, batch_size)` | ëª¨ë“  ë¶„í•  ë²•ë ¹ íŒŒì¼ ì²˜ë¦¬ |
| `show_stats()` | LanceDB í†µê³„ ì¶œë ¥ |
| `clear_model_cache()` | ëª¨ë¸ ë©”ëª¨ë¦¬ ì •ë¦¬ |

### ê¶Œì¥ ì„¤ì •

| GPU | batch_size | chunk_size (íŒŒì¼) |
|-----|------------|-------------------|
| RTX 3090 (24GB) | 64~128 | 5000 |
| RTX 5060 Ti (16GB) | 100 | 5000 |
| RTX 4080 (16GB) | 64 | 5000 |
| RTX 3070 (8GB) | 32 | 3000 |
| T4 (16GB) | 64 | 5000 |

### ìë™ ê°ì§€ ì„¤ì • (get_optimal_config)

ìŠ¤í¬ë¦½íŠ¸ê°€ GPU VRAMì„ ê°ì§€í•˜ì—¬ ìë™ìœ¼ë¡œ ìµœì  ì„¤ì •ì„ ì ìš©í•©ë‹ˆë‹¤:

| GPU VRAM | batch_size | num_workers | gc_interval |
|----------|------------|-------------|-------------|
| 20GB+ | 128 | 4 | 25 |
| 14GB+ | 100 | 4 | 20 |
| 8GB+ | 70 | 2 | 15 |
| 8GB ë¯¸ë§Œ | 50 | 2 | 10 |

---

## 10.5. í†µí•© ì„ë² ë”© í”„ë¡œì„¸ì„œ (v2)

### í´ë˜ìŠ¤ êµ¬ì¡°

2026-01-29 ë¦¬íŒ©í† ë§ìœ¼ë¡œ ë²•ë ¹/íŒë¡€ ì„ë² ë”© ë¡œì§ì´ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤.

```python
# ì¶”ìƒ ë² ì´ìŠ¤ í´ë˜ìŠ¤
class StreamingEmbeddingProcessor(ABC):
    """ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì„ë² ë”© í”„ë¡œì„¸ì„œ"""

    def __init__(self, data_type: str):
        self.data_type = data_type  # "ë²•ë ¹" | "íŒë¡€"
        self.device_info = get_device_info()
        self.optimal_config = get_optimal_config(self.device_info)
        self.store = LanceDBStore()

    def load_streaming(self, source_path: str) -> tuple:
        """ê°œìˆ˜ ì„¸ê¸° ìŠ¤í‚µ, ì¦‰ì‹œ ì‹œì‘"""

    def run(self, source_path: str, reset: bool, batch_size: int) -> dict:
        """í†µí•© ì‹¤í–‰ ë¡œì§"""

    # ì¶”ìƒ ë©”ì„œë“œ (ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)
    @abstractmethod
    def get_chunk_config(self) -> Any: ...
    @abstractmethod
    def extract_source_id(self, item: dict, idx: int) -> str: ...
    @abstractmethod
    def extract_text_for_embedding(self, item: dict) -> str: ...
    @abstractmethod
    def chunk_text(self, text: str, config: Any) -> List[tuple]: ...
    @abstractmethod
    def extract_metadata(self, item: dict) -> dict: ...
    @abstractmethod
    def create_batch_data(self) -> dict: ...
    @abstractmethod
    def add_to_batch(self, batch_data, source_id, chunk_idx, ...): ...
    @abstractmethod
    def save_batch(self, batch_data, embeddings) -> int: ...

# êµ¬í˜„ í´ë˜ìŠ¤
class LawEmbeddingProcessor(StreamingEmbeddingProcessor):
    """ë²•ë ¹ ì„ë² ë”© í”„ë¡œì„¸ì„œ"""

class PrecedentEmbeddingProcessor(StreamingEmbeddingProcessor):
    """íŒë¡€ ì„ë² ë”© í”„ë¡œì„¸ì„œ"""
```

### í†µì¼ëœ ë™ì‘

- **ê°œìˆ˜ ì„¸ê¸° ìŠ¤í‚µ**: ëŒ€ìš©ëŸ‰ íŒŒì¼ì—ì„œ ì¦‰ì‹œ ì‹œì‘
- **tqdm**: ì†ë„(it/s)ë§Œ í‘œì‹œ (ì§„í–‰ë¥  % ë¯¸í‘œì‹œ)
- **ìŠ¤íŠ¸ë¦¬ë°**: ijsonìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬
- **GC**: ë§¤ ë°°ì¹˜ë§ˆë‹¤ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
- **ì••ì¶•**: 50ë°°ì¹˜ë§ˆë‹¤ LanceDB compact

### ì‚¬ìš© ì˜ˆì‹œ

```python
# ìƒˆ í´ë˜ìŠ¤ ì§ì ‘ ì‚¬ìš©
processor = PrecedentEmbeddingProcessor()
stats = processor.run(
    source_path="precedents.json",
    reset=True,
    batch_size=100
)

# ê¸°ì¡´ í•¨ìˆ˜ (ë˜í¼) ì‚¬ìš© - í•˜ìœ„ í˜¸í™˜
stats = run_precedent_embedding("precedents.json", reset=True, batch_size=100)
stats = run_law_embedding("laws.json", reset=True, batch_size=100)
```

---

## 11. API ì‚¬ìš© ì˜ˆì‹œ

```python
from app.common.vectorstore import get_vector_store

# í™˜ê²½ë³€ìˆ˜ VECTOR_DB=lancedb ì„¤ì • í•„ìš”
store = get_vector_store()

# ë²•ë ¹ ë¬¸ì„œ ì¶”ê°€
store.add_law_documents(
    source_ids=["010719"],
    chunk_indices=[0],
    embeddings=[[0.1] * 1024],
    titles=["ë¯¼ë²•"],
    contents=["[ë²•ë ¹] ë¯¼ë²• ì œ750ì¡°: ë¶ˆë²•í–‰ìœ„ ì±…ì„..."],
    enforcement_dates=["2023-08-08"],
    departments=["ë²•ë¬´ë¶€"],
    law_types=["ë²•ë¥ "],
)

# íŒë¡€ ë¬¸ì„œ ì¶”ê°€
store.add_precedent_documents(
    source_ids=["84ë‚˜3990"],
    chunk_indices=[0],
    embeddings=[[0.2] * 1024],
    titles=["ì†í•´ë°°ìƒì²­êµ¬ì‚¬ê±´"],
    contents=["[íŒë¡€] ìˆ˜ë ¨ì˜ ì˜ë£Œì‚¬ê³  ì±…ì„..."],
    decision_dates=["1986-01-15"],
    court_names=["ì„œìš¸ê³ ë²•"],
    case_numbers=["84ë‚˜3990"],
    case_types=["ë¯¼ì‚¬"],
)

# ë²¡í„° ê²€ìƒ‰
results = store.search(query_embedding, n_results=10)

# ìœ í˜•ë³„ ê²€ìƒ‰
results = store.search_by_type(query_embedding, "íŒë¡€", n_results=10)

# í•„í„° ê²€ìƒ‰
results = store.search(
    query_embedding,
    n_results=10,
    where={"data_type": "íŒë¡€", "case_type": "ë¯¼ì‚¬"}
)

# source_idë¡œ ì „ì²´ ì²­í¬ ì¡°íšŒ
chunks = store.get_by_source_id("010719")

# í†µê³„
total = store.count()
law_count = store.count_by_type("ë²•ë ¹")
precedent_count = store.count_by_type("íŒë¡€")
```

---

## 12. ì„ë² ë”© ìºì‹± (Embedding Pipeline)

ë™ì¼ í…ìŠ¤íŠ¸ ì¬ì„ë² ë”© ë°©ì§€ë¥¼ ìœ„í•œ í•´ì‹œ ê¸°ë°˜ ë””ìŠ¤í¬ ìºì‹œ.

### ì‚¬ìš©ë²•

```python
from scripts.runpod_lancedb_embeddings import EmbeddingCache, create_embeddings

# ìºì‹œ ì´ˆê¸°í™”
cache = EmbeddingCache("./embedding_cache")

# ìºì‹œ ì¡°íšŒ í›„ ì—†ìœ¼ë©´ ê³„ì‚°
embedding = cache.get_or_compute("ë²•ë¥  í…ìŠ¤íŠ¸", create_embeddings)

# ìºì‹œ í†µê³„
stats = cache.get_stats()
# {'hits': 150, 'misses': 50, 'hit_rate': '75.0%', 'memory_cache_size': 200}

# ìºì‹œ ì •ë¦¬
cache.clear_memory_cache()  # ë©”ëª¨ë¦¬ë§Œ
cache.clear_all()           # ì „ì²´ (ë””ìŠ¤í¬ í¬í•¨)
```

### ìºì‹œ êµ¬ì¡°

```
embedding_cache/
â”œâ”€â”€ a1/                    # í•´ì‹œ ì• 2ê¸€ìë¡œ ë¶„ì‚°
â”‚   â”œâ”€â”€ a1b2c3d4...json
â”‚   â””â”€â”€ a1e5f6g7...json
â”œâ”€â”€ b2/
â”‚   â””â”€â”€ b2c3d4e5...json
â””â”€â”€ ...
```

---

## 13. ì„ë² ë”© í’ˆì§ˆ ê²€ì¦

ìœ ì‚¬/ë¹„ìœ ì‚¬ ë¬¸ì„œ ìŒìœ¼ë¡œ ì„ë² ë”© í’ˆì§ˆ í‰ê°€.

### ì‚¬ìš©ë²•

```python
from scripts.runpod_lancedb_embeddings import EmbeddingQualityChecker

checker = EmbeddingQualityChecker()

# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (ë²•ë¥  ë„ë©”ì¸ ê¸°ë³¸ ìŒ)
report = checker.quick_test()
# Similar pairs avg:    0.8542
# Dissimilar pairs avg: 0.3215
# Separation:           0.5327
# Quality:              GOOD

# ì»¤ìŠ¤í…€ í…ŒìŠ¤íŠ¸
similar_pairs = [
    ("ì†í•´ë°°ìƒ ì²­êµ¬ê¶Œ", "ì†í•´ë°°ìƒ ì²­êµ¬"),
    ("ë¯¼ë²• ì œ750ì¡°", "ë¯¼ë²•ìƒ ë¶ˆë²•í–‰ìœ„"),
]
dissimilar_pairs = [
    ("ë¯¼ë²• ì œ750ì¡°", "í˜•ë²• ì œ250ì¡°"),
    ("ì†í•´ë°°ìƒ ì²­êµ¬", "íšŒì‚¬ ì„¤ë¦½ ì ˆì°¨"),
]
report = checker.evaluate(similar_pairs, dissimilar_pairs)

# ë‘ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ì§ì ‘ ê³„ì‚°
sim = checker.compute_similarity("í…ìŠ¤íŠ¸1", "í…ìŠ¤íŠ¸2")
```

### í’ˆì§ˆ ê¸°ì¤€

| Separation | Quality | ì˜ë¯¸ |
|------------|---------|------|
| > 0.2 | GOOD | ìœ ì‚¬/ë¹„ìœ ì‚¬ ëª…í™•íˆ êµ¬ë¶„ |
| 0.1 ~ 0.2 | FAIR | êµ¬ë¶„ ê°€ëŠ¥í•˜ë‚˜ ê°œì„  í•„ìš” |
| < 0.1 | POOR | êµ¬ë¶„ ì–´ë ¤ì›€, ëª¨ë¸/ì²­í‚¹ ì ê²€ í•„ìš” |

---

## 14. PyTorch ìµœì í™” íŒ¨í„´

ìŠ¤í¬ë¦½íŠ¸ì— ì ìš©ëœ ìµœì í™” íŒ¨í„´ ìš”ì•½.

### ì ìš©ëœ íŒ¨í„´

| íŒ¨í„´ | í•¨ìˆ˜/í´ë˜ìŠ¤ | ì„¤ëª… |
|------|------------|------|
| ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ | `get_device_info()` | CUDA > MPS > CPU ìš°ì„ ìˆœìœ„ |
| ë©€í‹° GPU ì§€ì› | `get_optimal_cuda_device()` | VRAM ìµœëŒ€ GPU ì„ íƒ |
| ë©”ëª¨ë¦¬ ì •ë¦¬ | `clear_memory()` | GC + CUDA cache í†µí•© |
| ì¬í˜„ì„± | `set_seed()` | ëœë¤ ì‹œë“œ ê³ ì • |
| VRAM ê¸°ë°˜ ì„¤ì • | `get_optimal_config()` | ë°°ì¹˜ í¬ê¸° ìë™ ì¡°ì • |

### ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜

```python
from scripts.runpod_lancedb_embeddings import (
    clear_memory,       # GC + CUDA cache ì •ë¦¬
    set_seed,           # ëœë¤ ì‹œë“œ ê³ ì •
    print_memory_status,# ë©”ëª¨ë¦¬ ìƒíƒœ ì¶œë ¥
    get_optimal_cuda_device,  # ë©€í‹° GPU ì‹œ ìµœì  ë””ë°”ì´ìŠ¤
)

# ì¬í˜„ì„± í™•ë³´
set_seed(42, deterministic=False)

# ë©”ëª¨ë¦¬ ì •ë¦¬
clear_memory()

# í˜„ì¬ ë©”ëª¨ë¦¬ ìƒíƒœ
print_memory_status()
# [Memory] RAM: 8.2GB / 32.0GB (25.6%)
# [Memory] GPU: 2.1GB allocated, 4.0GB reserved, 3.5GB max
```

---

## 15. êµ¬í˜„ ì™„ë£Œ í˜„í™©

| í•­ëª© | ìƒíƒœ | ë¹„ê³  |
|------|------|------|
| ë‹¨ì¼ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ | âœ… ì™„ë£Œ | 20ê°œ ì»¬ëŸ¼ |
| JSON â†’ PostgreSQL ë¡œë“œ | âœ… ì™„ë£Œ | load_lancedb_data.py |
| PostgreSQL â†’ LanceDB ì„ë² ë”© | âœ… ì™„ë£Œ | create_lancedb_embeddings.py |
| RunPod ìŠ¤í¬ë¦½íŠ¸ | âœ… ì™„ë£Œ | runpod_lancedb_embeddings.py |
| ë¶„í•  ì²˜ë¦¬ (ëŒ€ìš©ëŸ‰) | âœ… ì™„ë£Œ | split_precedents, split_laws |
| í†µí•© í”„ë¡œì„¸ì„œ í´ë˜ìŠ¤ | âœ… ì™„ë£Œ | StreamingEmbeddingProcessor |
| ì„ë² ë”© ìºì‹± | âœ… ì™„ë£Œ | EmbeddingCache |
| í’ˆì§ˆ ê²€ì¦ | âœ… ì™„ë£Œ | EmbeddingQualityChecker |
| PyTorch ìµœì í™” | âœ… ì™„ë£Œ | clear_memory, set_seed ë“± |
| ê²€ìƒ‰ API í†µí•© | ğŸ”„ ì§„í–‰ì¤‘ | VectorStoreBase ì¸í„°í˜ì´ìŠ¤ |
